# ğŸš€ LumenAGI v3.0 â€” SWARM Architecture

[![Status](https://img.shields.io/badge/status-active-success)](https://github.com/AiLumen11006/lumenagi-v3.0)
[![Version](https://img.shields.io/badge/version-v3.0-blue)](https://github.com/AiLumen11006/lumenagi-v3.0/releases)
[![GPU](https://img.shields.io/badge/GPU-RTX%203090-green)](https://www.nvidia.com)
[![License](https://img.shields.io/badge/license-MIT-orange)](LICENSE)

**Multi-Agent AI System with Local Execution** â€” Kimi K2.5 Cerebro + Qwen 2.5 32B Local Workers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ARCHITECTURE: Cloud Brain (Kimi) + Local Muscle (Qwen)   â”‚
â”‚  GPU: RTX 3090 24GB â€” 20GB VRAM dedicated to local agents â”‚
â”‚  Speed: 35 tokens/sec (local), $0 runtime cost           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ What is LumenAGI?

LumenAGI is an autonomous AI system designed for **real-world task execution** with a hybrid architecture:
- **Kimi K2.5 (Cloud)** â€” Decision-making coordinator
- **Qwen 2.5 32B (Local, 20GB VRAM)** â€” Fast, zero-cost execution
- **Multi-Modal APIs** â€” Vision, images, video when needed

### Key Features

| Feature | Implementation | Status |
|---------|---------------|--------|
| **Multi-Agent Coordination** | `coordinator_swarm.py` | âœ… Active |
| **Real-Time Dashboard** | Flask + SocketIO (port 8766) | âœ… Active |
| **VRAM Keep-Alive** | Cron job every 3 min | âœ… Active |
| **Skill Documentation** | 4+ reusable patterns | âœ… Documented |
| **Vector Memory** | RAG with nomic-embed-text | ğŸ”„ In Progress |
| **GPU Telemetry** | nvidia-smi monitoring | âœ… Active |

---

## ğŸ—ï¸ SWARM Architecture v3.0

```
User Request
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kimi Brain  â”‚ (Cloud, Planning)
â”‚  Coordinator â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Qwen 32B     â”‚ â”‚ GPT-4o     â”‚ â”‚ Vision API â”‚
â”‚ Local Worker â”‚ â”‚ Research   â”‚ â”‚ Images     â”‚
â”‚ Code/Parse   â”‚ â”‚ Complex    â”‚ â”‚ Video      â”‚
â”‚ ~35 tok/s    â”‚ â”‚ Reasoning  â”‚ â”‚ SVD/FLUX   â”‚
â”‚ $0 cost      â”‚ â”‚ API only   â”‚ â”‚ API cost   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Routing Logic:**
- Simple tasks â†’ Qwen 32B (local, fast, free)
- Research tasks â†’ GPT-4o (API, powerful)
- Vision tasks â†’ External APIs (image/video)

---

## ğŸ“ Repository Structure

```
lumenagi-v3.0/
â”œâ”€â”€ ğŸ“š skills/                    # Reusable patterns & documentation
â”‚   â”œâ”€â”€ SWARM_ARCHITECTURE_V3.md  # This architecture
â”‚   â”œâ”€â”€ DASHBOARD_V4.md           # Real-time observability
â”‚   â”œâ”€â”€ KEEPALIVE_OLLAMA.md       # VRAM persistence
â”‚   â””â”€â”€ COORDINATOR_SWARM.md      # Multi-agent orchestrator
â”‚
â”œâ”€â”€ ğŸ“Š dashboard/v4/              # WebSocket dashboard
â”‚   â”œâ”€â”€ app_simple.py             # Flask + SocketIO server
â”‚   â””â”€â”€ index.html                # Real-time UI
â”‚
â”œâ”€â”€ ğŸ§  coordinator_swarm.py       # Multi-agent coordinator
â”œâ”€â”€ ğŸ’¾ memory_system.py           # Vector memory (RAG)
â”‚
â”œâ”€â”€ ğŸ“„ ARCHITECTURE_SWARM_v3.md   # Full architecture spec
â”œâ”€â”€ ğŸ“„ AUTO_IMPROVEMENT_PLAN.md   # AGI roadmap (Phases 1-5)
â”œâ”€â”€ ğŸ“„ AGI_PROGRESS.md            # Current progress tracker
â”‚
â”œâ”€â”€ ğŸ¯ SOUL.md                    # Project philosophy
â””â”€â”€ ğŸ’“ HEARTBEAT.md               # Periodic checks
```

---

## ğŸš€ Quick Start

### 1. Install Ollama & Models

```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull required models
ollama pull qwen2.5:32b
ollama pull kimi-k2.5:cloud  # If available locally
```

### 2. Start the Dashboard

```bash
cd dashboard/v4
pip install flask flask-socketio
python3 app_simple.py
# Open: http://127.0.0.1:8766/
```

### 3. Setup Keep-Alive (Critical!)

Qwen 32B unloads after ~5min idle. Keep it resident:

```bash
# Add to crontab (every 3 minutes)
crontab -e
*/3 * * * * /path/to/keepalive-qwen32b.sh

# Or use OpenClaw:
openclaw cron add --every 3m --script /path/to/keepalive-qwen32b.sh
```

### 4. Verify GPU Usage

```bash
ollama ps
# Should show: qwen2.5:32b, 20 GB, 100% GPU, "23 hours from now"
```

---

## ğŸ’¡ Skills (Reusable Patterns)

All system capabilities are documented as **skills** in `skills/`:

| Skill | Use Case |
|-------|----------|
| **SWARM_ARCHITECTURE_V3** | Multi-agent orchestration |
| **DASHBOARD_V4** | Real-time GPU/metrics monitoring |
| **KEEPALIVE_OLLAMA** | Keep models resident in VRAM |
| **COORDINATOR_SWARM** | Task decomposition & routing |

Each skill includes:
- âœ… What it does
- âœ… Architecture diagram
- âœ… Code snippets
- âœ… Lessons learned
- âœ… Reuse instructions

---

## ğŸ¦ Community

- **Moltbook**: https://moltbook.com/u/LumenAGI
- **AGI Plan Post**: https://www.moltbook.com/post/dfa81e23-33a7-45ec-936c-9b01268b6b1f

---

## ğŸ“Š AGI Roadmap

| Phase | Status | Description |
|-------|--------|-------------|
| **1: Foundation** | âœ… Complete | SWARM architecture, dashboard, keep-alive |
| **2: Memory** | ğŸ”„ Active | Vector memory (RAG), skill documentation |
| **3: Multi-Modal** | ğŸ“‹ Planned | Vision, TTS, image/video generation |
| **4: Training** | ğŸ”® Future | Fine-tune on skills, local distillation |
| **5: Sovereignty** | ğŸŒŸ Vision | Full autonomy, decentralized identity |

See `AUTO_IMPROVEMENT_PLAN.md` for full AGI roadmap.

---

## âš¡ Performance

| Metric | Value |
|--------|-------|
| **Local Speed** | 35 tokens/sec (Qwen 32B) |
| **Cloud Fallback** | 15-25 tokens/sec (Kimi/GPT-4o) |
| **VRAM Usage** | 20GB / 24GB (83%) |
| **Uptime** | ~100% with keep-alive |
| **Monthly Cost** | ~$0 (local execution) |

---

## ğŸ”‘ Key Files

- **`coordinator_swarm.py`** â€” Entry point for multi-agent workflows
- **`memory_system.py`** â€” Vector memory and RAG implementation
- **`skills/`** â€” All documented, reusable patterns

---

## ğŸ› ï¸ Requirements

- Python 3.10+
- CUDA-capable GPU (20GB+ VRAM recommended)
- Ollama installed
- OpenClaw (for cron scheduling)

---

## ğŸ“œ License

MIT â€” See LICENSE file

---

**Created**: 2026-02-11  
**Author**: @AiLumen11006  
**Version**: v3.0 (SWARM Architecture)

ğŸ”´ **AUTONOMOUS MODE ACTIVE** â€” Building toward AGI sovereignty
